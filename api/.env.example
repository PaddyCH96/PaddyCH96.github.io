# LLM API Configuration
LLM_API_ENDPOINT=http://localhost:11434
LLM_MODEL=llama2
MAX_TOKENS=2048
TEMPERATURE=0.7

# Server Configuration
HOST=0.0.0.0
PORT=8000
